\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[scale=0.7,vmarginratio={1:2},heightrounded]{geometry}

\usepackage[numbers]{natbib}

% link support in pdf
\usepackage[colorlinks,allcolors=blue,breaklinks = true]{hyperref}

% images in pdf
\usepackage{graphicx}
\graphicspath{{Bilder/}}
% multiple images
\usepackage{subfigure}
% images float in text
\usepackage{float}

% url support
\usepackage{url}
% glossarie support
\usepackage[acronym, automake]{glossaries}
\makeglossaries
\loadglsentries{glossary}

% math libs
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{mathrsfs}

% Code formating
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

%Metadata
\title{Procedural Generation in the age of AI}
\author{Simon Hischier}
\date{June 2018}

\begin{document}

%Titlepage
\begin{titlepage}
%\maketitle
\centering
\vspace{1cm}
	{\scshape\LARGE Fachhochschule Luzern HSLU \par}
	\vspace{1cm}
	{\scshape\Large Studiengang Digital Ideation \par}
	{\scshape\Large Bachelor \par}
	{\scshape\Large Seminararbeit, 4. Semester\par}
	\vspace{1.5cm}
	{\huge\bf Procedural Generation in the age of AI\par}
	
	\vspace{10cm}
	{\Large Simon Hischier\par}
	{\Large Modul Zukunftsforschung\par}
	{\Large Dozent Alan N. Shapiro\par}
	\vfill

% Bottom of the page
	{\large \today\par}
\end{titlepage}

%Table of Contents Page
\renewcommand{\contentsname}{Inhalt}
\tableofcontents
\newpage

%First real page
\section{Abstract}
This work does a juxtaposition between procedural generation with manually written algorithms and approaches with Machine Learning. The question leading through this essay therefore is: How does content creation in games differ between Procedural Content Generation and Machine Learning content creation? Machine Learning and Neural Networks are booming in the fields of big data and image recognition, only very few works address the artistic capabilities like googles deep dream and this work takes a look at balancing procedural solutions and Machine Learning solutions. The work first defines a few important terms and then lists different problemsolutions with procedural and with Machine Learning examples. We defined the basic terms, discussed the desire to controll the artistic vision, worked through various examples for both approaches and listed possible solutions to some problems occuring with either procedural or Machine Learning tasks. The goal of this work is to create awareness for creative Machine Learning utilisation and to highlight challenges in both systems.

\section{Definitions}
\subsection{Procedural Content Generation}
The term \gls{pcg} defines a form of content generation that is automated. The content is created through algorithmic processes and with few to no human interaction. This allows for the creation of bigger, more random looking, unique content with less to no artist interaction\cite{VanderLinden2014}.

\subsection{Artificial Intelligence}
In 1956 the Book Automata Studies\cite{McCarthy1956} layed the ground work for \gls{ai} and the Dartmouth summer research project on artificial intelligence marked the key event "to nail the flag to the mast." McCarthy is credited for coining the phrase “artificial intelligence” and solidifying the orientation of the field\cite{moor2006dartmouth}. The name \gls{ai} was used ever since for various applications. Ever since this key event \gls{ai} is defined based on the goal that is tried to beeing achieved. Bernard Marr lists them as following\cite{Marr2018}:
\begin{enumerate}
\item Build systems that think exactly like humans do ("strong AI"). 
\item Just get systems to work without figuring out how human reasoning works ("weak AI").
\item Use human reasoning as a model but not necessarily the end goal.
\end{enumerate}
Marr referes with "strong AI" and "weak AI" to the paper written by John Searle where he defines a strong \gls{ai} of beeing able to think and have a mind and a weak \gls{ai} that can only act like it thinks and has a mind. The paper is also known for the "Chinese Room" argument\cite{Searle1980}. More terms for an \gls{ai} classification exist like Artificial General Intelligence (AGI) and the Artificial Superintelligence (ASI). For this work we won't need more precise classifications and these classifications therefore are not further defined in this work. Bernard Marr continues to list the various definitions for \gls{ai}. While dictionaries list \gls{ai} with clear definitions, companies lack a clear definition and Marr extrapolates a definition from the companies research field. The dictionary definitions and his extrapolated definitions are listed here:
\begin{enumerate}
\item \textbf{The English Oxford Living Dictionary} "The theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision making, and translation between languages."
\item \textbf{Merriam-Webster}
\begin{enumerate}
\item A branch of computer science dealing with the simulation of intelligent behavior in computers.
\item The capability of a machine to imitate intelligent human behavior.
\end{enumerate}
\item \textbf{The Encyclopedia Britannica} "artificial intelligence (AI), the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings."
\item \textbf{Amazon} defines it as "the field of computer science dedicated to solving cognitive problems commonly associated with human intelligence, such as learning, problem solving, and pattern recognition."
\item \textbf{Google AI} "create smarter, more useful technology and help as many people as possible"
\item \textbf{Facebook AI Research} "advancing the file of machine intelligence and are creating new technologies to give people better ways to communicate."
\item \textbf{IBM}'s three areas of focus are "AI Engineering, building scalable AI models and tools; AI Tech where the core capabilities of AI such as natural language processing, speech and image recognition and reasoning are explored and AI Science, where expanding the frontiers of AI is the focus."\cite{Marr2018}
\end{enumerate}
This work is using the definition of the term \gls{ai} as listed in \textit{The Encyclopedia Britannica}. The fields described in this work can be categorized in the 3. objective listed by Marr "Use human reasoning as a model but not necessarily the end goal"\cite{Marr2018}.

\subsection{The Difference between AI, Machinelearning, Deeplearning}
\label{sec:AIMachinelearningDeeplearning}
As shown before, \gls{ai} is not a new phenomena and even \gls{ml} is known for quite some time. Although there is a great difference between \gls{ai}, \gls{ml} and \gls{dl}, each field is a subsets of the previous. While \gls{ai} still is a very broad term \gls{ml} and \gls{dl} are closer together. \gls{dl} introduces neuron simulation to \gls{ml} by creating discrete layers, connections and directions of data propagation\cite{MichaelCopeland2016}. The technology started to grow significantly around the year 2010. This seems to be related to the growing computational power and the immense amount of collected and stored data\cite{MichaelCopeland2016}. The illustration is showing the relationship between the 3 terms.
\begin{figure}[H]
	\includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{Deep_Learning_Icons_R5.png}
	\caption{Levels of AI as Image\cite{MichaelCopeland2016}.}
\end{figure}

\subsection{Often used Neural Networks}
\subsubsection{Convolution Neural Network}
The \gls{cnn} describes a method to reduce input data and enhance \gls{nn} performance. The convolution allows for faster calculations and reduces memory requirements. This advantages make \gls{cnn} very desirable for image recognition and voice recognition tasks and are widely used in these fields. If interested take a look at the Blogpost from Deshpande Adit\citep{DeshpandeAdit2016}.

\subsubsection{Recurrent Neural Networks}
As explained in \autoref{sec:AIMachinelearningDeeplearning} \gls{ml} is a broad term and includes a variety of models. The \gls{rnn} are networks for tasks where we need some kind of persistance. If we want to classify videoframes the network should have some kind of consistency\cite{Olah2015}. A network should persist the last seen data and not reclassify items every frame. Reclassifying without previous context could lead to different recognitions in every frame for the same object.

\subsubsection{Long short-term memory}
\gls{rnn} are good for persisting very recent information. Sentences are a great example: "Ships are built to float on \textit{water}". The \gls{rnn} is great in filling the end of this sentence. Problems arise when the information is needed a lot later. The more information is inbetween the contextual references the more unreiable a basic \gls{rnn} gets. Books for example can have references on the last page to the very beginning. For such tasks a \gls{lstm} model is the perfect fit. The \gls{lstm} network was introduced by Hochreiter Sepp and Urgen Schmidhuber\citep{Hochreiter1997}. A \gls{lstm} is a specialized version of an \gls{rnn} which is designed for these kind of tasks. Almost all \gls{rnn} tasks can be achieved with a \gls{lstm} \gls{rnn}\cite{Olah2015}.

\section{The artistic vision and the generation}\label{sec:visionVSgeneration}
Generating content for games is a fundamental artistic choice for game developers. The generation in various forms is generally linked to a decrease in the artistic vision, although generation itself can be the desired artistic expression. Designers have to step away from micro-controlling game parts like the environment, shapes, colors, enemy behaviours etc. Therefore games do include \gls{pcg} in different ways and in various depths. Big studios tend to stick to more controlled experiences and have more (human-)resources to ensure this vision. We define a list of various depths of \gls{pcg}:
\begin{enumerate}
\item \textbf{No Generation.} An example here might be \textit{Super Mario Bros.} (Nintendo, 1985) where everything was handplaced, drawn and animated. Mr. Miyamoto explains some details of the level creation in \textit{Super Mario Bros}. Level 1-1\cite{EurogamerMiyamotoInterview}.
\item \textbf{Content Generation in the game making phase.} \textit{The Elder Scrolls Oblivion} (Bethesda Softworks, 2006) used \gls{pcg} to generated most of the world before the artists curated it\cite{PCGamerCarterInterview}. An example of a widely used \gls{pcg} algorithm middleware for game studios is SpeedTree\cite{SpeedTree}.
\item \textbf{Gameplay (partially) definded or influenced} by \gls{pcg} such as the sidequests for \textit{The Elder Scrolls Skyrim} (Bethesda Softworks, 2011) which were endlessly generated\cite{Bertz2011} or Castles in \textit{Rogue Legacy} (Cellar Door Games, 2013) which are generated procedurally but the game has some kind of continuosity and progress on top of the castle runs\cite{Stanton2013}.
\item \textbf{Games almost completely generated.} \textit{Dwarf Fortress} (Dwarf Fortress, 2006) doesn't stop at the map generation. It starts out generating the history of the world and everything that happened before\cite{Champandard2012}.
\end{enumerate}
Games and even game genres do fall into these different depths of \gls{pcg}. A major role for this classification of games and game genres is the depth of artistic control or lack therefore\cite{VanderLinden2014}. Games that do rely more on \gls{pcg} tend to focus more on the fun gameplay rather then an intriguing story and complex characters. Further categorization and different methods of \gls{pcg} can be found in the Paper from van der Linden, Lopes and Bidarra\cite{VanderLinden2014}.

\section{Procedural Content Generation and AI}
As explained in \hyperref[sec:visionVSgeneration]{The artistic vision and the generation} there are various genres and games falling into different levels of \gls{pcg}. Due to the type of gameplay and game mechanics linked to \gls{pcg}, games with high levels of procedural generation can easily be identified. We hope \gls{ai} blurs the line between \gls{pcg} and handcrafted gameparts more. A goal for \gls{ai} components is to create \gls{pcg} games that are less distinguishable from handcrafted counterparts. By extending the \gls{pcg} with \gls{ai} we hope to have a more natural and handcrafted feel to \gls{pcg} type games. As \gls{ml} gets used more in games, the applications starts to vary further.

\section{Applications of Procedural Approaches}
Procedural generation of content varies wildly and can affect most gameparts. In \hyperref[sec:visionVSgeneration]{The artistic vision and the generation} we made an attempt to categorize the different stages and depths of automation. However the reason to use \gls{pcg} can range from necessity (memory limitations, more content to create than time to create it) to artistic choice (pattern and style generation). The \gls{pcg} algorithms allow to shift the artists focus away from the detail work to broader concepts. An example might be the world biomes in \textit{Minecraft} (Markus Persson, 2009) instead of exact placements of blocks and levelparts. \gls{pcg} has multiple facettes and listing the different reasons to use \gls{pcg} is not feasable in this work. What all procedural algorithms share in common is a tradeoff between disk space and computing time. A big advantage of \gls{pcg} compared to \gls{ml} is the great influence on the outcome and the artists controll over how exactly things get generated. With \gls{pcg} algorithms the artist has complete controll over the process of generating the drawback for this is an increasing amount of programming work and complexity. Another interesting property of \gls{pcg} is the curiosity involved in finding out what the algorithm generated. Eventhough the artist has complete controll over \textbf{how} content is generated they don't controll \textbf{what} exactly is generated, leaving said room for curiosity. Some unsorted and randomly picked examples of \gls{pcg} widely used are listed below.

\subsection{Level Generation}
Procedural Level Generation is around for a very long time. It was present during the arcade games because of the need to possibly play endlessly on the hunt for the high score. It got carried over to the personal computer, generating dungeons to provide unique experiences\cite{VanderLinden2014} and to counter floppy disk memory limitations. Currently one of the most famous level generators is used in \textit{Minecraft} (Markus Persson, 2009) where the endless worlds are used to feed the players curiosity. The strength of these systems is that worlds are replicable (see world-seeds in Minecraft), can be controlled and fine-tuned and don't necessarily need a lot of computational power. They are expandable, maintainable and errors in the level generation process can be checked and fixed. A drawback is the complexity (or lack therefore) of such generators. Worlds can look repetitive and empty.

\subsection{Text to Speech}
Procedural approaches of text to speech up until now were more on the functional side (see Microsoft Sam). Text to speech has great challenges and voices can sound very monotone, lack highlights and are in general not used in games. Games either hire voice actors to read the text examples or display the text as is.

\section{Applications of Neural Network systems}
In comparison to the procedural approach of extending the algorithm the \gls{nn} approach is a very top-down approach. A \gls{nn} needs a lot of computing resources and a great set of datapoints. \gls{ml} does need a lot more computational power then \gls{pcg} but those numbers are rapidly falling as shown by AlphaGo Zero\citep{Silver2017}. The user does not have to (neither can) finetune the parameters for the generation directly as is with the \gls{pcg}. The users can choose different \gls{nn} types and can only control the various \gls{ml} controllers which come with the \gls{nn}. There is no direct influence on the generation itself, the output can be changed by letting the \gls{ml} model guess and finetune its weights until it gets the desired output. This changes the workflow significantly and to use the network a user has to know what outcome is desired. This stands in direct opposition to procedural algorithms where the output is a result of the written code. With \gls{nn}s the artist decides on what the concept is which the \gls{nn} should learn and he then teaches the \gls{nn} to follow the concept. Testing such a \gls{nn} and evaluating corner cases is very labor intensive and debugging is not a real option. The big drawback when creating a new model is the need for existing data. The procedural algorithms can be programmed to work with a random number and data can optionally be fed into the algorithm to shape the outcome while developing. For a \gls{nn} to generate data in the desired way one has to first create a lot of examples that look like the desired outcome to train the network with. This is the biggest difference when working with \gls{nn} instead of procedural algorithms. To show a few examples of various \gls{nn} we list examples where the \gls{nn} \gls{ai} performs great. Note that the examples represent a small field of applications and the examples are randomly picked. This field is under extensive research and there are significant parts left out like image combination\cite{Luan2018}, style transfer, evolution of objects to name a few.

\subsection{Face representation in games}
An area where \gls{ai} is much more effective then handwritten procedrual approaches is face reconstruction and face mapping. Webcam feeds have no depth information and creating 3D faces from photos is a labor intensive work. Recent research shows \gls{ml} is capable of reconstructing and position mapping 3D avatars from single user images. It's robust, fast and stable\cite{Feng2018}. A large area in the games industry is avatar faces. Massive Multiplayer Games tend to have elaborate avatar creaton tools to customize the game character. Games like \textit{Arma} (Bohemia Interactive, 2013) are using the users voice in multiplayer sessions and try to synchronize the avatars lips with the players spoken words. Online chats with avatar representations such as \textit{VRChat} (VRChat Inc., 2017) have immersive VR worlds where players can walk and talk in a virtual environment. For streaming platforms like \textit{Twitch} (Amazon, 2011) a webcam feed is part of the majority of streams. All these different games, genres and platforms would benefit from some kind of reconstruction of the players face. \textit{Arma} could have the real user face represented in real-time in the game, non human avatars could use \gls{ai} to map the users lips and expressions on to the virtual avatars. Streamers could have their faces as 3D models or have an avatar instead of a live camera feed.

\subsection{Text to Speech}
Text is a big part of games. Extreme examples of games with word counts comparable to The Lord of the Rings book trilogy are present in the \gls{rpg} and the text adventure genre. For this games voicing every line is out of range for game studios and therefore players have to read most of the text. With a trained \gls{nn} it is possible to have a voice actor read example texts and let the \gls{nn} generate the voice from the written text in the game\cite{Shen2017}. Although a demonstration used 24.6 hours of training data this number can probably be reduced. Another paper shows, that even singing can be generated with 16 and 35 minutes of sentences read out\cite{Blaauw2017}. The later audio example lengths could potentially open doors for further applications of text to speech such as online chat using the users voice to generate spoken words for the other users.

\subsection{Game AI}
Something almost all games have is computer players controlled by \gls{ai}. There are a variety of different solutions to mimic human behaviour. The more complex a game is the harder it is to write comprehensible game \gls{ai}. Games like Go remain too complex to write an algorithm to calculate a winning strategy. There are simply too many complex situations and too many possible paths to explore. In this field \gls{dl} really showed its power and Alpha Go defeating the world champion was a major step in \gls{ai} development\cite{Silver2016}\cite{Silver2017}. While Alpha Go did need more hardwarepower then the usual gaming computer provides, OpenAI demonstrated a less powerhungry \gls{ai} for \textit{Dota 2} (Valve Corporation, 2013). At the International Tournament 2017 OpenAI demonstrated an \gls{ai} that beat Pro Players at the game reliably\cite{Openai2017}. The rules were more strict then a normal game of Dota 2 but given enough time and resources, an \gls{ai} that can beat professional teams is likely. These types of games are a big challenge to program computer players for because they allow for wacky situations, situations never seen before and asymmetric or incomplete information about the other players. An interesting task for \gls{ml} is creating an \gls{ai} that always remains at and adapts to the level of the human player. This is a colossal task and almost impossible to program by hand or with other approaches.

\subsection{Anti-Cheating}
Valve demonstrated a very significant increase in Anti-Cheat software effectiveness after they started to use \gls{dl}. Old methods of hardcoding different checks did and does only lead to an arms race with the cheat providers. The new approach requires the company to maintain a powerfull server. A big drawback is, that the company has to own a more powerfull \gls{nn} and have more complete information to not get outsmarted by cheat providers\cite{McDonald2018}.

\section{Level Generation compared}
Level generation can be done via \gls{ml} as shown by Adam Geitgey\citep{AdamGeitgey2016} or \gls{pcg} depending on the desired output. Both approaches could potentially be combined for a wider variety. What both approaches lack is the carefully curated and manually designed human aspect of levels. The amount of detail and teaching in a single \textit{Super Mario Bros.} (Nintendo, 1985) level\cite{EurogamerMiyamotoInterview} is still not feasible by both approaches.

\section{Conclusion}
In this work we learned about different applications for \gls{ml} and \gls{pcg} algorithms. The \gls{ml} field is still under heavy research and most of the \gls{ml} research is outside of the field of creative content generation. As \gls{ml} gets more popular more fields will be researched. From the different usecases we learned that \gls{ml} is a top-down approach to generate content and the \gls{pcg} is a bottom-up approach to generate content. This showed, that \gls{ml} takes a big upfront work before it can generate useful gameparts and users have to know upfront what they want. Further the goal of \gls{ml} was not to use as little hardware as possible which is one of \gls{pcg}s strengths. The different strengths of \gls{pcg} and \gls{ml} suggest, that \gls{ml} is an extension in the content generation toolbox rather then a replacement. \gls{ml} is opening up a lot of new potential fields for content generation where classic \gls{pcg} was insufficient. The computing requirements show, that some \gls{nn} can operate in realtime already and that other \gls{nn} can still be heavily optimized as the Alpha Go team showed. But at the moment most \gls{ml} applications in games will still be used during the production of the game instead of during the playtime. Both approaches still lack the thought through creative possibilities possible by humans as explained with the \textit{Super Mario Bros.} level. \gls{ml} is very hard to control and finetune and therefore depending on the area of application is a lot more labor intensive.

\section{References and Acronyms}

\printglossaries

%\renewcommand{\refname}{myBibliography}
\bibliography{myBibliography}
%\bibliographystyle{unsrtnat}
%\bibliographystyle{plainnat}
\bibliographystyle{unsrt}
%\bibliography{myBibliography}

%list the figures and tables in contents
%\addcontentsline{toc}{section}{\listfigurename}
%\addcontentsline{toc}{section}{\listtablename}

%print list
\listoffigures
%\listoftables

%\nocite{*}

\end{document}